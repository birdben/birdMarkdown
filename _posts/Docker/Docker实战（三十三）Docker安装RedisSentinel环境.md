---
title: "Docker实战（三十三）Docker安装RedisSentinel环境"
date: 2017-07-27 18:20:16
tags: [Docker命令, Dockerfile, Redis]
categories: [Docker]
---

Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身（包括它的很多客户端）都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。

我这里使用docker-compose构建3个redis节点（1个master，2个slave）。然后单独构建3个sentinel节点负责监控这3个redis节点。

节点信息如下：

Name|Role|IP|Inner Port|Outter Port
---|---|---|---|---
redis1|master|172.22.0.2|6379|6379
redis2|slave|172.22.0.3|6379|6479
redis3|slave|172.22.0.4|6379|6579
sentinel1||172.22.0.5|16379|16379
sentinel2||172.22.0.6|16379|16479
sentinel3||172.22.0.7|16379|16579

#### sentinel.conf配置文件

```
# 默认端口26379
port 26379

# 文件路径
dir "/sentinel/data"

# 日志路径
logfile "/sentinel/logs/sentinel.log"

# 后台运行（这里一定不要使用后台运行，否则Docker容器无法启动）
daemonize no 

# 格式：sentinel <option_name> <master_name> <option_value>；
# 该行的意思是：监控的master的名字叫做T1（自定义）,地址为127.0.0.1:10086，行尾最后的一个2代表在sentinel集群中，多少个sentinel认为masters死了，才能真正认为该master不可用了。
sentinel myid 65d4e099ea7828f119a3dffea3a103c2a5e84f55

# sentinel会向master发送心跳PING来确认master是否存活，如果master在“一定时间范围”内不回应PONG或者是回复了一个错误消息，那么这个sentinel会主观地(单方面地)认为这个master已经不可用了(subjectively down, 也简称为SDOWN)。而这个down-after-milliseconds就是用来指定这个“一定时间范围”的，单位是毫秒，默认30秒。
sentinel monitor T1 172.17.0.2 6379 2

# failover过期时间，当failover开始后，在此时间内仍然没有触发任何failover操作，当前sentinel将会认为此次failoer失败。默认180秒，即3分钟。
sentinel down-after-milliseconds T1 15000

# 在发生failover主备切换时，这个选项指定了最多可以有多少个slave同时对新的master进行同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave处于不能处理命令请求的状态。
sentinel failover-timeout T1 120000

# sentinel 连接设置了密码的主和从
sentinel auth-pass T1 root

# 下面的配置是sentinel自动生成的（可以先忽略，因为第一次启动之后才会生成，而且会随着自动切换而变化）
# Generated by CONFIG REWRITE
```

#### redis.conf配置文件

这里只列举了关键配置

```
# 复制选项，slave复制对应的master。（如果master宕机，重新选举出新的master，该项配置会被sentinel重新rewrite）
slaveof 172.22.0.2 6379

# 如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。
masterauth "root"

# 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：
# 1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。
# 2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。
slave-serve-stale-data yes

# 作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。
slave-read-only yes
```

#### sentinel.log日志变化

docker-compose启动成功后，观察sentinel.log日志文件的变化。

##### sentinel1.log日志

```
...
1:X 28 Jul 20:44:30.830 # Sentinel ID is e377117faf74f4b5e523f161a8e446ea0adcadd6
1:X 28 Jul 20:44:30.832 # +monitor master T1 172.22.0.2 6379 quorum 2
1:X 28 Jul 20:44:33.247 * +sentinel sentinel bc0f73149d9cc462734f2ffa28067a687a2bef0f 172.22.0.7 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:33.850 * +sentinel sentinel 14f975ba408e6674db406119b0abf83bf5ff8d2c 172.22.0.6 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:40.889 * +slave slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:40.896 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
```

##### sentinel2.log日志

```
...
1:X 28 Jul 20:44:31.732 # Sentinel ID is 14f975ba408e6674db406119b0abf83bf5ff8d2c
1:X 28 Jul 20:44:31.738 # +monitor master T1 172.22.0.2 6379 quorum 2
1:X 28 Jul 20:44:31.740 * +slave slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:32.832 * +sentinel sentinel e377117faf74f4b5e523f161a8e446ea0adcadd6 172.22.0.5 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:33.248 * +sentinel sentinel bc0f73149d9cc462734f2ffa28067a687a2bef0f 172.22.0.7 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:41.791 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
```

##### sentinel3.log日志

```
...
1:X 28 Jul 20:44:31.133 # Sentinel ID is bc0f73149d9cc462734f2ffa28067a687a2bef0f
1:X 28 Jul 20:44:31.135 # +monitor master T1 172.22.0.2 6379 quorum 2
1:X 28 Jul 20:44:32.832 * +sentinel sentinel e377117faf74f4b5e523f161a8e446ea0adcadd6 172.22.0.5 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:33.850 * +sentinel sentinel 14f975ba408e6674db406119b0abf83bf5ff8d2c 172.22.0.6 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:41.182 * +slave slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 20:44:41.188 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
```

从上面的sentinel日志中可以看出：

- Sentinel ID：每个sentinel节点都生成一个唯一ID
- +monitor master T1 172.22.0.2 6379：监控的master节点的日志
- +sentinel sentinel：是sentinel的各个节点之间互相通信的日志
- +slave slave：是发现了master下的2个slave节点的日志

#### sentinel.conf配置文件变化

前面已经提到了，当sentinel监控到redis节点，会rewrite（重写）sentinel.conf配置文件的内容。

##### sentinel1.conf配置文件

```
# Generated by CONFIG REWRITE
sentinel config-epoch T1 0
sentinel leader-epoch T1 0
sentinel known-slave T1 172.22.0.3 6379
sentinel known-slave T1 172.22.0.4 6379
sentinel known-sentinel T1 172.22.0.6 26379 14f975ba408e6674db406119b0abf83bf5ff8d2c
sentinel known-sentinel T1 172.22.0.7 26379 bc0f73149d9cc462734f2ffa28067a687a2bef0f
sentinel current-epoch 0
```

##### sentinel2.conf配置文件

```
# Generated by CONFIG REWRITE
sentinel config-epoch T1 0
sentinel leader-epoch T1 0
sentinel known-slave T1 172.22.0.3 6379
sentinel known-slave T1 172.22.0.4 6379
sentinel known-sentinel T1 172.22.0.7 26379 bc0f73149d9cc462734f2ffa28067a687a2bef0f
sentinel known-sentinel T1 172.22.0.5 26379 e377117faf74f4b5e523f161a8e446ea0adcadd6
sentinel current-epoch 0
```

##### sentinel3.conf配置文件

```
# Generated by CONFIG REWRITE
sentinel config-epoch T1 0
sentinel leader-epoch T1 0
sentinel known-slave T1 172.22.0.3 6379
sentinel known-slave T1 172.22.0.4 6379
sentinel known-sentinel T1 172.22.0.6 26379 14f975ba408e6674db406119b0abf83bf5ff8d2c
sentinel known-sentinel T1 172.22.0.5 26379 e377117faf74f4b5e523f161a8e446ea0adcadd6
sentinel current-epoch 0
```

- sentinel config-epoch：
- sentinel leader-epoch：
- sentinel known-slave：是已经发现的slave节点信息
- sentinel known-sentinel：是已经发现的sentinel节点信息
- sentinel current-epoch：当前的版本

#### 尝试failover操作

这里我们将redis1节点停掉，然后观察sentinel.log日志文件和sentinel.conf配置文件的变化。

> 注意：
> 
> 其实redis.conf配置文件也sentinel进行rewrite操作了，只是变化了slaveof，将原来master节点变成slave节点，然后将所有slave节点的slaveof配置成新的master节点。

##### sentinel1.log日志文件

```
...
1:X 28 Jul 21:07:00.692 # +sdown master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.816 # +new-epoch 1
1:X 28 Jul 21:07:00.821 # +vote-for-leader bc0f73149d9cc462734f2ffa28067a687a2bef0f 1
1:X 28 Jul 21:07:01.797 # +odown master T1 172.22.0.2 6379 #quorum 3/2
1:X 28 Jul 21:07:01.798 # Next failover delay: I will not start a failover before Fri Jul 28 21:11:01 2017
1:X 28 Jul 21:07:01.817 # +config-update-from sentinel bc0f73149d9cc462734f2ffa28067a687a2bef0f 172.22.0.7 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.819 # +switch-master T1 172.22.0.2 6379 172.22.0.4 6379
1:X 28 Jul 21:07:01.821 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.4 6379
1:X 28 Jul 21:07:01.823 * +slave slave 172.22.0.2:6379 172.22.0.2 6379 @ T1 172.22.0.4 6379
```

##### sentinel2.log日志文件

```
...
1:X 28 Jul 21:07:00.715 # +sdown master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.794 # +odown master T1 172.22.0.2 6379 #quorum 2/2
1:X 28 Jul 21:07:00.797 # +new-epoch 1
1:X 28 Jul 21:07:00.799 # +try-failover master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.808 # +vote-for-leader 14f975ba408e6674db406119b0abf83bf5ff8d2c 1
1:X 28 Jul 21:07:00.811 # bc0f73149d9cc462734f2ffa28067a687a2bef0f voted for bc0f73149d9cc462734f2ffa28067a687a2bef0f 1
1:X 28 Jul 21:07:00.824 # e377117faf74f4b5e523f161a8e446ea0adcadd6 voted for bc0f73149d9cc462734f2ffa28067a687a2bef0f 1
1:X 28 Jul 21:07:01.919 # +config-update-from sentinel bc0f73149d9cc462734f2ffa28067a687a2bef0f 172.22.0.7 26379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.922 # +switch-master T1 172.22.0.2 6379 172.22.0.4 6379
1:X 28 Jul 21:07:01.925 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.4 6379
1:X 28 Jul 21:07:01.927 * +slave slave 172.22.0.2:6379 172.22.0.2 6379 @ T1 172.22.0.4 6379
1:X 28 Jul 21:07:16.937 # +sdown slave 172.22.0.2:6379 172.22.0.2 6379 @ T1 172.22.0.4 6379
```

##### sentinel3.log日志文件

```
...
1:X 28 Jul 21:07:00.735 # +sdown master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.793 # +odown master T1 172.22.0.2 6379 #quorum 3/2
1:X 28 Jul 21:07:00.795 # +new-epoch 1
1:X 28 Jul 21:07:00.797 # +try-failover master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.806 # +vote-for-leader bc0f73149d9cc462734f2ffa28067a687a2bef0f 1
1:X 28 Jul 21:07:00.811 # 14f975ba408e6674db406119b0abf83bf5ff8d2c voted for 14f975ba408e6674db406119b0abf83bf5ff8d2c 1
1:X 28 Jul 21:07:00.823 # e377117faf74f4b5e523f161a8e446ea0adcadd6 voted for bc0f73149d9cc462734f2ffa28067a687a2bef0f 1
1:X 28 Jul 21:07:00.894 # +elected-leader master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.896 # +failover-state-select-slave master T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.970 # +selected-slave slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:00.972 * +failover-state-send-slaveof-noone slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.027 * +failover-state-wait-promotion slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.750 # +promoted-slave slave 172.22.0.4:6379 172.22.0.4 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.751 # +failover-state-reconf-slaves master T1 172.22.0.2 6379
1:X 28 Jul 21:07:01.811 * +slave-reconf-sent slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:02.767 * +slave-reconf-inprog slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:02.769 * +slave-reconf-done slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.2 6379
1:X 28 Jul 21:07:02.869 # +failover-end master T1 172.22.0.2 6379
1:X 28 Jul 21:07:02.871 # +switch-master T1 172.22.0.2 6379 172.22.0.4 6379
1:X 28 Jul 21:07:02.873 * +slave slave 172.22.0.3:6379 172.22.0.3 6379 @ T1 172.22.0.4 6379
1:X 28 Jul 21:07:02.874 * +slave slave 172.22.0.2:6379 172.22.0.2 6379 @ T1 172.22.0.4 6379
1:X 28 Jul 21:07:17.934 # +sdown slave 172.22.0.2:6379 172.22.0.2 6379 @ T1 172.22.0.4 6379
```

详细步骤解释请参考：

- http://www.cnblogs.com/zhoujinyi/p/5570024.html

#### failover之后sentinel.conf配置文件的变化

##### sentinel1.conf配置文件

```
sentinel monitor T1 172.22.0.4 6379 2
...
# Generated by CONFIG REWRITE
sentinel config-epoch T1 1
sentinel leader-epoch T1 1
sentinel known-slave T1 172.22.0.3 6379
sentinel known-slave T1 172.22.0.2 6379
sentinel known-sentinel T1 172.22.0.6 26379 14f975ba408e6674db406119b0abf83bf5ff8d2c
sentinel known-sentinel T1 172.22.0.7 26379 bc0f73149d9cc462734f2ffa28067a687a2bef0f
sentinel current-epoch 1
```

##### sentinel2.conf配置文件

```
sentinel monitor T1 172.22.0.4 6379 2
...
# Generated by CONFIG REWRITE
sentinel config-epoch T1 1
sentinel leader-epoch T1 1
sentinel known-slave T1 172.22.0.2 6379
sentinel known-slave T1 172.22.0.3 6379
sentinel known-sentinel T1 172.22.0.7 26379 bc0f73149d9cc462734f2ffa28067a687a2bef0f
sentinel known-sentinel T1 172.22.0.5 26379 e377117faf74f4b5e523f161a8e446ea0adcadd6
sentinel current-epoch 1
```

##### sentinel3.conf配置文件

```
sentinel monitor T1 172.22.0.4 6379 2
...
# Generated by CONFIG REWRITE
sentinel config-epoch T1 1
sentinel leader-epoch T1 1
sentinel known-slave T1 172.22.0.2 6379
sentinel known-slave T1 172.22.0.3 6379
sentinel known-sentinel T1 172.22.0.6 26379 14f975ba408e6674db406119b0abf83bf5ff8d2c
sentinel known-sentinel T1 172.22.0.5 26379 e377117faf74f4b5e523f161a8e446ea0adcadd6
sentinel current-epoch 1
```

sentinel.conf配置文件变化主要有三点：

- sentinel monitor监控的新的master已经变成172.22.0.4了（之前是172.22.0.2）
- sentinel config-epoch leader-epoch current-epoch的版本号都从0变成1
- sentinel known-slave也将之前的master（172.22.0.2）变成了slave

failover之后redis3节点被选举成新的master节点，客户端对redis的操作一切正常。

参考文章：

- http://www.redis.cn/topics/sentinel.html
- http://www.cnblogs.com/zhoujinyi/p/5570024.html
- http://www.cnblogs.com/zhoujinyi/p/5569462.html
- https://segmentfault.com/a/1190000002680804
- https://segmentfault.com/a/1190000002685515
- http://www.jianshu.com/p/ece45f22aeba